{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 4: Máquinas de vectores soporte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adrián López Ortiz\n",
    "\n",
    "46265190T\n",
    "\n",
    "p42loora@uco.es\n",
    "\n",
    "Esqueleto proporcionado por: Alberto Jurado Roldán (i62juroa@uco.es)\n",
    "    \n",
    "**Introducción a los Modelos Computacionales**\n",
    "    \n",
    "4º Curso del Grado Superior en Ingeniería Informática con Mención en Computación\n",
    "    \n",
    "$1^{er}$ Cuatrimestre del Curso 2019-20\n",
    "    \n",
    "Córdoba, 20-11-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÍNDICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- [Introducción](#Introducción)\n",
    "- [Bases de datos sintéticas](#Bases-de-datos-sintéticas)\n",
    "    - [Instalación de `libsvm`](#Instalación-de-libsvm)\n",
    "    - [Representación 2D de las SVMs](#Representación-2D-de-las-SVMs)\n",
    "        - [Pregunta [1]](#Pregunta-[1])\n",
    "    - [Primer *dataset* de ejemplo](#Primer-dataset-de-ejemplo)\n",
    "        - [Pregunta [2]](#Pregunta-[2])\n",
    "        - [Pregunta [3]](#Pregunta-[3])\n",
    "    - [Segundo *dataset* de ejemplo](#Segundo-dataset-de-ejemplo)\n",
    "        - [Pregunta [4]](#Pregunta-[4])\n",
    "        - [Pregunta [5]](#Pregunta-[5])\n",
    "    - [Tercer *dataset* de ejemplo](#Tercer-dataset-de-ejemplo)\n",
    "        - [Pregunta [6]](#Pregunta-[6])\n",
    "        - [Pregunta [7]](#Pregunta-[7])\n",
    "    - [Interfaz de consola](#Interfaz-de-consola)\n",
    "        - [Pregunta [8]](#Pregunta-[8])\n",
    "        - [Pregunta [9]](#Pregunta-[9])\n",
    "        - [Pregunta [10]](#Pregunta-[10])\n",
    "        - [Pregunta [11]](#Pregunta-[11])\n",
    "- [Bases de datos reales](#Bases-de-datos-reales)\n",
    "    - [Base de datos *noMNIST*](#Base-de-datos-noMNIST)\n",
    "        - [Pregunta [12]](#Pregunta-[12])\n",
    "        - [Pregunta [13]](#Pregunta-[13])\n",
    "    - [Base de datos clasificación de *spam*](#Base-de-datos-clasificación-de-spam)\n",
    "        - [Pregunta [14]](#Pregunta-[14])\n",
    "        - [Pregunta [15]](#Pregunta-[15])\n",
    "        - [Pregunta [16]](#Pregunta-[16])\n",
    "        - [Pregunta [17]](#Pregunta-[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica, vamos a realizar distintos ejercicios para entender mejor el funcionamiento de las máquinas de vectores soporte (*Support Vector Machines*, SVMs) en problemas de clasificación. Las SVMs se han convertido, desde hace algunos años, en el estado del arte en problemas de reconocimiento de patrones y es importante conocer su funcionamiento y como responden a sus distintos parámetros. La práctica se realizará utilizando la librerı́a `libsvm`, que es una de las implementaciones más populares y eficientes que se disponen actualmente. En todos los casos, consideraremos la versión “C-SVC”, incluida en `libsvm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases de datos sintéticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta primera parte de la práctica, utilizaremos una serie de experimentos sobre bases de datos sintéticas, que nos ayudarán a entender cómo funcionan las SVMs y qué efectos producen sobre los resultados los dos parámetros que hay que especificar para entrenarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de `libsvm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica vamos a utilizar Python. `scikit-learn` ya trae un clasificador que aplica el algoritmo SVC, utilizando la implementación de `libsvm`. En concreto, el clasificador es `sklearn.svm.SVC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación 2D de las SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la representación gráfica en dos dimensiones desde Python, vamos a utilizar el *script* [`libsvm.py`](data/libsvm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Abre este [*script*](data/libsvm.py) y explica su contenido. Podrás ver que se utiliza el primer dataset de ejemplo y se realiza la representación gráﬁca del SVM. Comenta qué tipo de *kernel* se está utilizando y cuáles son los parámetros de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 23 10:14:36 2017\n",
    "\n",
    "@author: pedroa\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# Cargar el dataset\n",
    "data = pd.read_csv('dataset1.csv',header=None)\n",
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "svm_model = svm.SVC(kernel='linear',C=200)\n",
    "svm_model.fit(X, y)\n",
    "\n",
    "# Representar los puntos\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired)\n",
    "\n",
    "# Representar el hiperplano separador\n",
    "plt.axis('tight')\n",
    "# Extraer límites\n",
    "x_min = X[:, 0].min()\n",
    "x_max = X[:, 0].max()\n",
    "y_min = X[:, 1].min()\n",
    "y_max = X[:, 1].max()\n",
    "\n",
    "# Crear un grid con todos los puntos y obtener el valor Z devuelto por la SVM\n",
    "XX, YY = np.mgrid[x_min:x_max:500j, y_min:y_max:500j]\n",
    "Z = svm_model.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "# Hacer un plot a color con los resultados\n",
    "Z = Z.reshape(XX.shape)\n",
    "plt.pcolormesh(XX, YY, Z > 0)\n",
    "plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo se puede observar en el código, primero importamos la librerías con los métodos necesarios para su ejecución.\n",
    "\n",
    "A continuación, se carga el dataset1 en la variable data, que a su vez, reparte la información en dos variables,X e Y. La primera contiene Las dos primeras columnas del dataset, es decir, la información y en la variable Y,se guarda la clase a la que pertenecerá cada elemento de X (1 ó 2), respectivamente.\n",
    "\n",
    "Luego, nos disponemos a entrenar el modelo SVM. Para ello, se configura de forma que el kernel es de tipo **lineal** y que la penalización por error es de **C = 200**. Tras esto, se pone a entrenar.\n",
    "\n",
    "Una vez entrenado, se representan gracias a los métodos de la librería *matplotlib.pyplot* los puntos obtenidos:\n",
    "\n",
    "- Primero, se dice que se trabajará en la figura 1, luego se limpia dicha ventana pra mostrar en ella los puntos obtenidos con el método scatter que los posiciona a un orden Z de 10 para evitar que el área de cada cúster los tape.\n",
    "- Luego se dibujar el hiperplano separador y se extraen los límites mínimo y máximo de cada coordenada.\n",
    "- A continuación, se crea un grid con todos los puntos y se obtiene mediante el método svm_model_decision_function la Z devuelta por el SVM.\n",
    "- Por último se ajusta la Z obtenida en el punto anterior con el tamaño de los datos y se dibuja la gráfica y se muestra por pantalla, poniendo como margen de cada clase con el hiperplano un valor absoluto de 0.5.\n",
    "    \n",
    "Tras esta explicación se pasará a ejecutar el código y mostrar la imagen obtenida:\n",
    "\n",
    "![Gráfica obtenida tras ejecutar el código explicado.](images/Figure_1.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer *dataset* de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta el [*script*](data/libsvm.py) mencionado anteriormente pero comenta las lı́neas correspondientes a la representación gráfica de la SVM, para ver solo los puntos del *dataset* (representación similar a la de Figura 1, [`dataset1.csv`](data/dataset1.csv))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 1](images/f1.png)\n",
    "**<center>Figura 1: *Dataset* sintético o tipo *toy* #1.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Intuitivamente, ¿qué hiperplano crees que incurrirá en un menor error de test en la tarea de separar las dos clases de puntos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se mostrará en una imagen editada cuál creo que sería el mejor hiperplano para obtener un menor error de test:\n",
    "\n",
    "![Gráfica con menor error de test.](images/Figure_2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte del ejercicio, vamos a utilizar una SVM lineal, es decir, una SVM donde la separación de las dos clases será una lı́nea recta. La forma de especificar los parámetros del algoritmo SVC en Python puede consultarse en http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html.\n",
    "\n",
    "Vamos a probar a utilizar distintos valores para el parámetro $C$. De manera informal, podemos decir que el parámetro $C$ es un parámetro que define cuánto vamos a penalizar el hecho de que se cometan errores en la clasificación. Un valor de $C$ muy grande resultará en una SVM que cometerá el mı́nimo número posible de errores, mientras que un valor pequeño de $C$ favorecerá el que se obtenga un clasificador con el máximo margen, aunque se cometan errores. Por supuesto, esto está relacionado con el posible sobre-entrenamiento (aprendizaje de patrones ruidosos de entrenamiento que puedan despistar al modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Modifica el [*script*](data/libsvm.py) probando varios valores de $C$, en concreto, $C \\in \\{10^{−2}, 10^{−1}, 10^{0}, 10^{1}, 10^{2}, 10^{3}, 10^{4}\\}$. Observa qué sucede, explica porqué y escoge el valor más adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostraremos una tabla con los CCR para cada valor de C así cómo las gráficas generadas en cada una de las ejecuciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo *dataset* de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, trabajaremos con el dataset de la Figura 2 ([`dataset2.csv`](data/dataset2.csv))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 2](images/f2.png)\n",
    "**<center>Figura 2: *Dataset* sintético o tipo *toy* #2.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Prueba a lanzar una SVM lineal con los valores para $C$ que se utilizaron en la [pregunta anterior](#Pregunta-[3]). ¿Consigues algún resultado satisfactorio en el sentido de que no haya errores en el conjunto de entrenamiento? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conseguir hiperplanos de separación no lineales, las SVMs utilizan el llamado *truco del kernel* que, explicado de manera informal, construye un modelo lineal en un espacio de muchas dimensiones y lo proyecta de nuevo al espacio original, resultando en un modelo no lineal. Esto se consigue mediante el uso de funciones de *kernel* aplicadas sobre cada uno de los patrones de entrenamiento. El *kernel* más común es el *kernel* RBF, también llamado Gaussiano. Para poder aplicarlo, el usuario tiene que especificar un parámetro adicional ($\\gamma$, gamma, en `libsvm` $\\gamma = 1/radio$). Un radio alto tiende a soluciones más suaves, con menor sobre-entrenamiento, mientras que un radio de *kernel* pequeño tiende a producir mayor sobre-entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 3](images/f3.png)\n",
    "**<center>Figura 3: *Dataset* sintético o tipo *toy* #2 bien clasificado.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Propón una configuración de SVM no lineal (utilizando el *kernel* tipo RBF o Gaussiano) que resuelva el problema. El resultado deberı́a ser similar al de la Figura 3. ¿Qué valores has considerado para $C$ y para $\\gamma$?. Además, incluye un ejemplo de una configuración de parámetros que produzca sobre-entrenamiento y otra que produzca infra-entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tercer *dataset* de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a trabajar con el dataset de la Figura 4 ([`dataset3.csv`](data/dataset3.csv))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 4](images/f4.png)\n",
    "**<center>Figura 4: *Dataset* sintético o tipo *toy* #3.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">En este caso, ¿es el dataset linealmente separable? A primera vista, ¿detectas puntos que presumiblemente sean outliers? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 5](images/f5.png)\n",
    "**<center>Figura 5: *Dataset* sintético o tipo *toy* #3 bien clasificado.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lanza una SVM para clasificar los datos, con objeto de obtener un resultado lo más parecido al de la Figura 5. Ajusta el ancho del kernel en el intervalo $\\gamma \\in \\{0,02, 0,2, 2, 200\\}$. Ajusta el parámetro de coste en el intervalo $C \\in \\{0,02, 0,2, 2, 200\\}$. Establece el valor de los parámetros óptimos. Además, incluye un ejemplo de una configuración de parámetros que produzca sobre-entrenamiento y otra que produzca infra-entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfaz de consola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque estamos utilizando la interfaz de Python, vamos a especificar algunas caracterı́sticas de la interfaz de consola de [`libsvm`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/), para conocer mejor el proceso de entrenamiento de una SVM. La interfaz de consola de `libsvm` está compuesta de tres ficheros ejecutables o programas, que pueden ser invocados desde la consola:\n",
    "- `svm-scale`: Estandariza el fichero de una base de datos, para que sea posible procesarlo con el clasificador SVM. Ten en cuenta que, utilizando un *kernel* tipo RBF, todas las variables de entrada deben estar en la misma escala, sino algunas variables recibirán más importancia que otras a la hora del cálculo de distancias.\n",
    "- `svm-train`: Entrena un modelo SVM para un fichero de base de datos. El resultado del entrenamiento se guarda en un fichero con extensión `.model`.\n",
    "- `svm-predict`: Utiliza un modelo ya entrenado para ver como generaliza en una nueva base de datos (que debe tener la misma estructura). Es decir, realiza la fase de *test* del clasificador, comprobando cómo funciona para datos que no se han utilizado durante el entrenamiento.\n",
    "\n",
    "Supongamos que tenemos dos ficheros de datos `train.libsvm` y `test.libsvm`. El proceso de entrenamiento estándar de una SVM implicarı́a, en primer lugar, entrenar la SVM utilizando `svm-train` y el fichero `train.libsvm`, generando un modelo SVM. En segundo lugar, utilizarı́amos el programa `svm-predict` para ver qué tal generaliza el modelo SVM sobre los datos `test.libsvm`.\n",
    "\n",
    "Si utilizamos la clase `sklearn.svm.SVC` de `scikit-learn`, la estandarización tendremos que aplicarla nosotros, haciendo uso del objeto [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Aquı́ tienes un pequeño ejemplo de cómo se pueden estandarizar los datos:\n",
    ">```python\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "Por otro lado, la clase `sklearn.model_selection.StratifiedShuffleSplit` realiza una o varias particiones de una base de datos de forma “estratificada”, es decir, manteniendo la proporción de patrones de cada clase en la base de datos [original](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Vamos a reproducir este proceso en Python. Divide el *dataset* sintético [`dataset3.csv`](data/dataset3.csv) en dos subconjuntos aleatorios de forma **estratificada**, con un 75 % de patrones en *train* y un 25 % de patrones en *test*. Realiza el proceso de entrenamiento completo (estandarización, entrenamiento y predicción), utilizando los valores de $C$ y $\\gamma$ que obtuviste en la [última pregunta](#Pregunta-[7]). Comprueba el porcentaje de buena clasificación que se obtiene para el conjunto de test. Repite el proceso más de una vez para comprobar que los resultados dependen mucho de la semilla utilizada para hacer la partición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso tiene un pequeño inconveniente y es que es necesario especificar un valor para el parámetro $C$ y un valor para el parámetro $\\gamma$ (ancho del *kernel*, para el caso en que queramos un clasificador no lineal) y, como ya viste en la primera parte de la práctica, estos parámetros son muy sensibles. Para evitar esto, existe una forma de ajustar automáticamente los parámetros, siguiendo el siguiente proceso de validación cruzada anidada tipo K-fold:\n",
    "1. Realizamos una partición tipo $K$-fold (donde $K$ es un parámetro) de los datos de entrenamiento. Es decir, dividimos los datos de entrenamiento en $K$ subconjuntos disjuntos.\n",
    "2. Para cada combinación de parámetros, realizamos $K$ entrenamientos. Para cada entrenamiento $k$ de los $K$ totales:\n",
    "    - a) Utilizamos el subconjunto k como conjunto de test y el resto de subconjuntos como conjunto de entrenamiento.\n",
    "    - b) Acumulamos el error de test en una variable.\n",
    "\n",
    "   Al terminar, calculamos el error medio cometido durante los K entrenamientos. El proceso de validación cruzada se repite completo para todas las combinaciones posibles de parámetros $C$ y $\\gamma$. Por ejemplo, si vamos a darle 9 valores a $C$ y 9 valores a $\\gamma$ y vamos a realizar una validación cruzada de tipo 5-fold, esto implica que realizaremos $9 \\times 9 \\times 5 = 405$ entrenamientos. Nótese que hasta el momento no se han utilizado los datos de *test*.\n",
    "3. Escogemos la combinación de parámetros que resultó en el menor error medio en el paso anterior y tomamos esos valores de parámetros como los valores óptimos.\n",
    "4. Utilizando esos parámetros, repetimos el proceso de entrenamiento pero ahora considerando el conjunto completo de entrenamiento (sin hacer subconjuntos).\n",
    "5. Con el modelo obtenido en el paso anterior, comprobamos cuál es el error en *test* (fase real de *test*).\n",
    "\n",
    "En `scikit-learn`, la búsqueda de parámetros la podemos realizar haciendo uso del objeto [`sklearn.grid search.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html). Aquı́ tienes un pequeño ejemplo:\n",
    "\n",
    ">```python\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "Cs = np.logspace(-5, 15, num=11, base=2)\n",
    "Gs = np.logspace(-15, 3, num=9, base=2)\n",
    "optimo = GridSearchCV(estimator=svm_model, param_grid=dict(C=Cs,gamma=Gs), n_jobs=-1,cv=5)\n",
    "optimo.fit(X_train,y_train)\n",
    "print optimo.score(X_test,y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Amplı́a el código anterior para realizar el entrenamiento de la [pregunta 8](#Pregunta-[8]) sin necesidad de especificar los valores de $C$ y $\\gamma$. Compara los valores óptimos obtenidos para ambos parámetros con los que obtuviste a mano. Extiende el rango de valores a explorar, si es que lo consideras necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">¿Qué inconvenientes observas en ajustar el valor de los parámetros “a mano”, viendo el porcentaje de buena clasificación en el conjunto de test (lo que se hizo en la [pregunta 8](#Pregunta-[8]))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Para estar seguros de que has entendido como se realiza la búsqueda de parámetros, implementa de forma manual (sin usar `GridSearchCV`) la *validación cruzada anidada tipo K-fold* expuesta en esta sección. Te puede ser útil el uso de listas por compresión y la clase `StratifiedKFold`. Compara los resultados con los que obtienes usando `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases de datos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez te has familiarizado con el clasificador SVM y con su versiones lineal y no lineal, en esta parte de la práctica vamos a abordar distintos problemas reales, con objeto de ver su aplicabilidad en bases de datos más complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de datos *noMNIST*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta base de datos, originariamente, está compuesta por 200000 patrones de entrenamiento y 10000 patrones de *test*, y un total de 10 clases. No obstante, para la práctica que nos ocupa, se ha reducido considerablemente el tamaño de la base de datos para realizar las pruebas en menor tiempo. Por lo tanto la base de datos que se utilizará está compuesta por 900 patrones de entrenamiento y 300 patrones de *test*. Está formada por un conjunto de letras (de la *a* a la *f*) escritas con difererentes tipografı́as o simbologı́as. Están ajustadas a una rejilla cuadrada de\n",
    "$28 \\times 28$ pı́xeles. Las imágenes están en escala de grises en el intervalo [$[−1,0; +1,0]$](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html). Cada uno de los pı́xeles forman parte de las variables de entrada (con un total de $28 \\times 28 = 784$ variables de entrada) y las clases se corresponden con la letra escrita (*a*, *b*, *c*, *d*, *e* y *f*, con un total de 6 clases). La figura 6 representa un subconjunto de los 180 patrones del conjunto de entrenamiento, mientras que la figura 7 representa un subconjunto de 180 letras del conjunto de test. Además, todas las letras, ordenadas dentro de cada conjunto, están en los ficheros [`train_img_nomnist.tar.gz`](data/train_img_nomnist.tar.gz) y [`test_img_nomnist.tar.gz`](data/test_img_nomnist.tar.gz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 6](images/f6.png)\n",
    "**<center>Figura 6: Subconjunto de letras del conjunto de entrenamiento</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 7](images/f7.png)\n",
    "**<center>Figura 7: Subconjunto de letras del conjunto de *test*</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Utiliza el script que desarrollaste en la [pregunta 9](#Pregunta-[9]) para entrenar esta base de datos. Observe el valor de CCR obtenido para el conjunto de generalización y compáralo con el obtenido en prácticas anteriores. El proceso puede demorarse bastante. Al finalizar, toma nota de los valores óptimos obtenidos para los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Localiza dónde se especifica el valor de $K$ para la validación cruzada interna y el rango de valores que se han utilizado para los parámetros $C$ y $\\gamma$. ¿Cómo podrı́as reducir el tiempo computacional necesario para realizar el experimento?. Prueba a establecer $K = 3$, $K = 5$ y $K = 10$ y compara, utilizando una tabla, los tiempos computacionales obtenidos y los resultados de CCR en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de datos clasificación de *spam*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los campos donde se utiliza el aprendizaje automático con un mayor éxito es la detección automática de *spam* en servidores de correo. Como dato significativo, ten en cuenta que el correo que recibes cada dı́a en tu cuenta de la Universidad de Córdoba (UCO) es solo un $5\\%$ de los correos reales que te llegan, de manera que el $95\\%$ restante es detectado y descartado automáticamente por filtros anti-*spam*. La mayorı́a de estos filtros utilizan internamente técnicas de clasificación binaria (correo tipo *spam*, $y = 1$, o no *spam*, $y = 0$) y cada vez está ganando mayor aceptación el uso de SVM. En esta sección, vamos a explicar los pasos que se llevan a cabo para preprocesar el texto de un correo y convertirlo en un vector de caracterı́sticas que podamos utilizar como entrada en cualquier clasificador. Posteriormente, se te pedirá que utilices SVM para clasificar una base de datos real.\n",
    "\n",
    "Imaginemos un correo cuyo cuerpo sea como el de la Figura 8. Podemos observar cómo este correo contiene una URL, una dirección de correo electrónico (al final), números y una cantidad en dólares. Muchos e-mails tendrán este tipo de cosas (direcciones de correo, URLs) pero, seguramente, el valor concreto (la URL concreta o el correo concreto) serán diferentes en cada e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    ">> Anyone knows how much it costs to host a web portal ?\n",
    ">>\n",
    "Well, it depends on how many visitors youre expecting. This can be\n",
    "anywhere from less than 10 bucks a month to a couple of $100. You\n",
    "should checkout http://www.rackspace.com/ or perhaps Amazon EC2 if\n",
    "youre running something big..\n",
    "To unsubscribe yourself from this mailing list, send an email to:\n",
    "groupname-unsubscribe@egroups.com\n",
    "```\n",
    "\n",
    "**<center>Figura 8: Ejemplo de correo</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, para la tarea concreta de clasificación (es *spam* o no), te interesa el hecho de que el correo contenga una dirección URL o un e-mail o un número, pero no su valor concreto. Por tanto, el proceso que vamos a seguir “normaliza” todas las URLs para que se traten del mismo modo, al igual que todos los números, todas las direcciones de correo, etc. Para ello, cada vez que aparezca en nuestro correo un dirección `http`, la reemplazaremos por la palabra reservada `httpaddr` que indica que habı́a una dirección. Esto está demostrado que mejora el porcentaje de buena clasificación en detección de *spam*, porque casi siempre los *spammers* cambian de forma aleatoria las direcciones URL (y ası́ es más difı́cil detectarlos).\n",
    "\n",
    "Se te va a proporcionar una base de datos de correos que es parte del repositorio [*SpamAssassin\n",
    "Public Corpus*](http://spamassassin.apache.org/publiccorpus/). Cada correo de esta base de datos ha recibido el siguiente preprocesamiento:\n",
    "1. Todo el correo ha sido escrito en letras minúsculas (es decir, “`InDICAtE`” se va a tratar igual que “`Indicate`” o que “`indicate`”). A menudo, los *spammers* usan esta técnica para evitar ser detectados.\n",
    "2. Eliminar todo código HTML: Todos los correos serán procesados como texto plano, de manera que se elimina cualquier etiqueta de formato de tipo HTML.\n",
    "3. Normalizar las URL: Todas las URL se reemplazan por `httpaddr`.\n",
    "4. Normalizar las direcciones de e-mail: Todos las direcciones de e-mail se reemplazan por `emailaddr`.\n",
    "5. Normalizar los números: Todos los números se reemplazan por `number`.\n",
    "6. Normalizar los dólares: Todos los signos de dolar ($, asociados con frecuencia a correos de *spam*) se reemplazan por `dollar`.\n",
    "7. *Stemming* de palabras: El *stem* de una palabra es su raı́z. Para la detección de *spam* es buena idea utilizar las raı́ces de las palabras, en lugar de las palabras completas. Por ejemplo, las palabras “`discount`”, “`discounts`”, “`discounted`” y “`discounting`” se reemplazan todas por “`discount`”. Hay programas (*stemmers*) que realizan este proceso de manera automática, utilizando para ello diccionarios especı́ficos.\n",
    "8. Quitar todo lo que no son palabras, por ejemplo, signos de puntuación o sı́mbolos poco frecuentes. Además, todos los espacios, tabuladores o saltos de lı́neas que vayan consecutivos son sustituidos por un solo carácter de espacio.\n",
    "\n",
    "El resultado de todos estos pasos sobre el correo anterior puede verse en la Figura 9. Con esta representación del correo es mucho más fácil extraer caracterı́sticas que transformen el correo en un vector de números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    "anyon know how much it cost to host a web portal well it depend on how mani visitor your\n",
    "expect thi can be anywher from less than number buck a month to a coupl of\n",
    "dollarnumb you should checkout httpaddr or perhap amazon ecnumb if your run someth\n",
    "big to unsubscrib yourself from thi mail list send an email to emailaddr\n",
    "```\n",
    "\n",
    "**<center>Figura 9: Ejemplo de correo ya preprocesado</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras este paso, debemos elegir cuáles de las palabras que tenemos como resultado vamos a utilizar para clasificar *spam*. A esto se le llama lista de vocabulario. En el caso que nos ocupa, se han seleccionado 1899 palabras, que son las que aparecen con más frecuencia. Estas palabras están en el fichero [`vocab.txt`](data/vocab.txt) y se muestran también en la Figura 10. Estas palabras son aquellas que aparecı́an al menos 100 veces en el total de e-mails de la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    "1 aa\n",
    "2 ab\n",
    "3 abil\n",
    "...\n",
    "916 know\n",
    "...\n",
    "1898 zero\n",
    "1899 zip\n",
    "```\n",
    "\n",
    "**<center>Figura 10: Lista de vocabulario</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando esta lista de vocabulario, el e-mail de la Figura 9 queda reducido a un conjunto de ı́ndices que representan cada una de las palabras (suponiendo que la palabra esté en el vocabulario, sino, simplemente se ignora por ser una palabra muy rara). El resultado de esa transformación puede verse en la Figura 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    "86 916 794 1077 883 370 1699 790 1822 1831 883 431 1171 794 1002 1893 1364 592 1676 238\n",
    "162 89 688 945 1663 1120 1062 1699 375 1162 479 1893 1510 799 1182 1237 810 1895\n",
    "1440 1547 181 1699 1758 1896 688 1676 992 961 1477 71 530 1699 531\n",
    "```\n",
    "\n",
    "**<center>Figura 11: Ejemplo de correo preprocesado y del que se han extraı́do los ı́ndices de las palabras.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde el punto de vista de la detección de spam, nos interesa si la palabra del vocabulario\n",
    "aparece, pero no en qué orden. Por tanto, el último paso transforma el vector de ı́ndices anterior\n",
    "en un vector de valores binarios. Para nuestro caso tendremos un vector $x \\in \\mathbb{R}^{1899}$ y la posición\n",
    "i valdrá 1 ($x_i = 1$) si la palabra del $i$-ésima del vocabulario aparece en el e-mail ($x_i = 0$ si no\n",
    "aparece). Este vector será el vector que se use para clasificar si el correo es o no *spam*. Usando esta\n",
    "representación, da igual que las palabras aparezcan más de una vez.\n",
    "\n",
    "Dispones de dos ficheros de datos donde todo este proceso ya se ha realizado. El fichero de\n",
    "entrenamiento contiene 4000 correos, mientras que el de test tiene 1000 correos. Ambos utilizan\n",
    "la lista de vocabulario de 1899 palabras contenida en [`vocab.txt`](data/vocab.txt). Por tanto, cada patrón tiene\n",
    "1899 valores binarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Debes entrenar un modelo **lineal** de SVM con valores $C = 10^{−2}$, $C = 10^{−1}$, $C = 10^{0}$ y $C = 10^{1}$. Para ello, utiliza un script similar al que usaste para la [pregunta 9](#Pregunta-[9]). Compara los resultados y establece la mejor configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Para la mejor configuración, construye la matriz de confusión y establece cuáles son los correos en los que la SVM se equivoca. Consulta las variables de entrada para los correos que no se clasifican correctamente y razona el motivo. Ten en cuenta que para cada patrón, cuando $x_i$ es igual a 1 quiere decir que la palabra $i$-ésima del vocabulario aparece, al menos una vez, en el correo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Compara los resultados obtenidos con los resultados utilizando una red RBF. Para ello, haz uso del programa desarrollado en la práctica anterior. Utiliza solo una semilla (la que mejor resultado obtenga)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta [17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Entrena una SVM no lineal y compara los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
